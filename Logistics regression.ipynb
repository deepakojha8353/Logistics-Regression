{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKBsO7+IWeFB5W7r3J8l+R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZZAKkkKEI8a","executionInfo":{"status":"ok","timestamp":1755015383930,"user_tz":-330,"elapsed":2573,"user":{"displayName":"deepak ojha","userId":"09519587383351388865"}},"outputId":"4233c593-3f07-4bfa-86cf-befcc1eef881"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.956140350877193\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["#1. Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy. (Use Dataset from sklearn package)\n","import pandas as pd\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Load dataset\n","data = load_breast_cancer()\n","df = pd.DataFrame(data.data, columns=data.feature_names)\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(df, data.target, test_size=0.2, random_state=42)\n","\n","# Train model\n","model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)\n","\n","# Predictions and accuracy\n","y_pred = model.predict(X_test)\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"]},{"cell_type":"code","source":["#2.Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n","model_l2 = LogisticRegression(penalty='l2', max_iter=1000)\n","model_l2.fit(X_train, y_train)\n","\n","print(\"Coefficients:\", model_l2.coef_)\n","print(\"Accuracy:\", accuracy_score(y_test, model_l2.predict(X_test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tv6_RiFzExEA","executionInfo":{"status":"ok","timestamp":1755015506231,"user_tz":-330,"elapsed":138,"user":{"displayName":"deepak ojha","userId":"09519587383351388865"}},"outputId":"1f94e604-16e5-4887-f36e-8044ad755a82"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Coefficients: [[ 2.09981182  0.13248576 -0.10346836 -0.00255646 -0.17024348 -0.37984365\n","  -0.69120719 -0.4081069  -0.23506963 -0.02356426 -0.0854046   1.12246945\n","  -0.32575716 -0.06519356 -0.02371113  0.05960156  0.00452206 -0.04277587\n","  -0.04148042  0.01425051  0.96630267 -0.37712622 -0.05858253 -0.02395975\n","  -0.31765956 -1.00443507 -1.57134711 -0.69351401 -0.84095566 -0.09308282]]\n","Accuracy: 0.956140350877193\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}]},{"cell_type":"code","source":["#3.Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report. (Use Dataset from sklearn package)\n","from sklearn.datasets import load_iris\n","iris = load_iris()\n","X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n","\n","model_ovr = LogisticRegression(multi_class='ovr', max_iter=1000)\n","model_ovr.fit(X_train, y_train)\n","\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, model_ovr.predict(X_test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJtZ9gFZFBQU","executionInfo":{"status":"ok","timestamp":1755015574925,"user_tz":-330,"elapsed":26,"user":{"displayName":"deepak ojha","userId":"09519587383351388865"}},"outputId":"6d49a571-4f24-48a1-bc8c-9ade8aa054a8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        10\n","           1       1.00      0.89      0.94         9\n","           2       0.92      1.00      0.96        11\n","\n","    accuracy                           0.97        30\n","   macro avg       0.97      0.96      0.97        30\n","weighted avg       0.97      0.97      0.97        30\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["#4.Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n","from sklearn.model_selection import GridSearchCV\n","\n","params = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n","grid = GridSearchCV(LogisticRegression(max_iter=1000), params, cv=5)\n","grid.fit(X_train, y_train)\n","\n","print(\"Best Parameters:\", grid.best_params_)\n","print(\"Best CV Accuracy:\", grid.best_score_)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_23nPqjFRea","executionInfo":{"status":"ok","timestamp":1755015663329,"user_tz":-330,"elapsed":959,"user":{"displayName":"deepak ojha","userId":"09519587383351388865"}},"outputId":"8668fa25-391a-4608-9cd4-e077494c3ecd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n","Best CV Accuracy: 0.9583333333333334\n"]}]},{"cell_type":"code","source":["#5.Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n","from sklearn.preprocessing import StandardScaler\n","\n","# Without scaling\n","model_no_scale = LogisticRegression(max_iter=1000)\n","model_no_scale.fit(X_train, y_train)\n","acc_no_scale = accuracy_score(y_test, model_no_scale.predict(X_test))\n","\n","# With scaling\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","model_scaled = LogisticRegression(max_iter=1000)\n","model_scaled.fit(X_train_scaled, y_train)\n","acc_scaled = accuracy_score(y_test, model_scaled.predict(X_test_scaled))\n","\n","print(\"Without Scaling Accuracy:\", acc_no_scale)\n","print(\"With Scaling Accuracy:\", acc_scaled)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyZJk781FiHB","executionInfo":{"status":"ok","timestamp":1755015705669,"user_tz":-330,"elapsed":21,"user":{"displayName":"deepak ojha","userId":"09519587383351388865"}},"outputId":"2f52d41e-d501-4567-b509-65b484e7eb4e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Without Scaling Accuracy: 1.0\n","With Scaling Accuracy: 1.0\n"]}]}]}